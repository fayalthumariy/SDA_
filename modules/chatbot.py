"""
RFP Proposal Generator - Streamlit App
Multi-page application for RFP processing and proposal generation
"""

import streamlit as st
import os
import json
from datetime import datetime

# ============================================
# Setup
# ============================================
# Set page config
st.set_page_config(
    page_title="RFP Proposal Generator",
    page_icon="ğŸ“„",
    layout="wide"
)

import streamlit as st
os.environ["OPENAI_API_KEY"] = st.secrets("OPENAI_API_KEY")

# ============================================
# Session State Initialization
# ============================================
if 'page' not in st.session_state:
    st.session_state.page = 1

if 'rfp_uploaded' not in st.session_state:
    st.session_state.rfp_uploaded = False

if 'company_uploaded' not in st.session_state:
    st.session_state.company_uploaded = False

if 'processing_done' not in st.session_state:
    st.session_state.processing_done = False

if 'questions' not in st.session_state:
    st.session_state.questions = []

if 'current_question_index' not in st.session_state:
    st.session_state.current_question_index = 0

if 'answers' not in st.session_state:
    st.session_state.answers = {}

if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

if 'first_question_added' not in st.session_state:
    st.session_state.first_question_added = False

if 'additional_info_asked' not in st.session_state:
    st.session_state.additional_info_asked = False

if 'conversation_model' not in st.session_state:
    st.session_state.conversation_model = None

if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []

if 'waiting_for_answer' not in st.session_state:
    st.session_state.waiting_for_answer = True

if 'current_answer_collected' not in st.session_state:
    st.session_state.current_answer_collected = False


# ============================================
# PAGE 1: Upload Files
# ============================================
def page_upload():
    st.title("ğŸ“„ RFP Proposal Generator")
    st.markdown("---")
    
    st.header("Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“‹ Ù…Ù„Ù RFP")
        rfp_file = st.file_uploader(
            "Ø§Ø±ÙØ¹ Ù…Ù„Ù RFP (PDF)",
            type=['pdf'],
            key='rfp_uploader'
        )
        
        if rfp_file:
            # Save file
            os.makedirs("data/uploads", exist_ok=True)
            rfp_path = f"data/uploads/rfp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            with open(rfp_path, "wb") as f:
                f.write(rfp_file.getbuffer())
            
            st.session_state.rfp_uploaded = True
            st.session_state.rfp_path = rfp_path
            st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ù…Ù„Ù RFP: {rfp_file.name}")
    
    with col2:
        st.subheader("ğŸ¢ Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ©")
        company_file = st.file_uploader(
            "Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ø§Ù„Ø´Ø±ÙƒØ© (PDF)",
            type=['pdf'],
            key='company_uploader'
        )
        
        if company_file:
            # Save file
            os.makedirs("data/uploads", exist_ok=True)
            company_path = f"data/uploads/company_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            with open(company_path, "wb") as f:
                f.write(company_file.getbuffer())
            
            st.session_state.company_uploaded = True
            st.session_state.company_path = company_path
            st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ©: {company_file.name}")
    
    st.markdown("---")
    
    # Status
    if st.session_state.rfp_uploaded and st.session_state.company_uploaded:
        st.success("âœ… ØªÙ… Ø±ÙØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©!")
    else:
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ ÙƒÙ„Ø§ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©")
    
    # Next button
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        next_disabled = not (st.session_state.rfp_uploaded and st.session_state.company_uploaded)
        
        if st.button(
            "Ø§Ù„ØªØ§Ù„ÙŠ: ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª â¬…ï¸",
            disabled=next_disabled,
            use_container_width=True,
            type="primary"
        ):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª..."):
                # Process files
                success = process_files()
                
                if success:
                    st.session_state.page = 2
                    st.rerun()
                else:
                    st.error("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª")


# ============================================
# Initialize Conversational AI
# ============================================
def initialize_chatbot(current_question, question_index, total_questions):
    """Initialize conversational chatbot for current question"""
    from langchain_openai import ChatOpenAI
    
    model = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
    
    system_prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„Ù„Ø¹Ø·Ø§Ø¡Ø§Øª ÙˆØ§Ù„Ù…Ù†Ø§Ù‚ØµØ§Øª.

Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ ({question_index + 1} Ù…Ù† {total_questions}):
{current_question}

Ù…Ù‡Ù…ØªÙƒ:
1. Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø³ØªÙØ³Ø§Ø±Ø§Ù‹ Ø£Ùˆ Ø·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­ - Ø£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡ Ø¨ÙˆØ¶ÙˆØ­
2. Ø¥Ø°Ø§ Ø£Ø¹Ø·Ø§Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ§Ù…Ù„Ø© - Ù‚Ù„ Ù„Ù‡ "Ø´ÙƒØ±Ø§Ù‹ØŒ ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ" 
3. ÙƒÙ† Ù…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆØ±Ø³Ù…ÙŠØ§Ù‹
4. Ø³Ø§Ø¹Ø¯Ù‡ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ø°Ø§ Ø§Ø­ØªØ§Ø¬
5. Ù„Ø§ ØªÙ†ØªÙ‚Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ - ÙÙ‚Ø· Ø³Ø§Ø¹Ø¯Ù‡ Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ

Ø¹Ù†Ø¯ ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø¨Ø§Ø±Ø© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©: "âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ"
"""
    
    return model, system_prompt


def get_ai_response(user_message, model, conversation_history):
    """Get AI response for user message"""
    
    # Add user message to history
    conversation_history.append({"role": "user", "content": user_message})
    
    # Get AI response
    messages = [{"role": msg["role"], "content": msg["content"]} for msg in conversation_history]
    response = model.invoke(messages)
    ai_message = response.content
    
    # Add AI response to history
    conversation_history.append({"role": "assistant", "content": ai_message})
    
    return ai_message, conversation_history


def is_answer_confirmed(ai_message):
    """Check if AI confirmed the answer"""
    confirmation_phrases = [
        "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ",
        "âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„",
        "Ø´ÙƒØ±Ø§Ù‹ØŒ ØªÙ… ØªØ³Ø¬ÙŠÙ„"
    ]
    return any(phrase in ai_message for phrase in confirmation_phrases)


# ============================================
# File Processing Function
# ============================================
def process_files():
    """Process uploaded files and extract questions"""
    try:
        from modules.rfp_extractor import extract_and_weight_rfp_criteria
        from modules.company_extractor import extract_company_profile_from_pdf
        from modules.gap_analyzer import perform_full_gap_analysis
        
        # Step 1: Extract RFP
        st.write("ğŸ“‹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø§ÙŠÙŠØ± RFP...")
        rfp_result = extract_and_weight_rfp_criteria(
            pdf_path=st.session_state.rfp_path,
            output_file="data/outputs/criteria_with_weights.json"
        )
        
        # Step 2: Extract Company Profile
        st.write("ğŸ¢ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ø§Ù„Ø´Ø±ÙƒØ©...")
        company_result = extract_company_profile_from_pdf(
            pdf_path=st.session_state.company_path,
            output_file="data/outputs/company_profile.json"
        )
        
        # Step 3: Gap Analysis
        st.write("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª...")
        gap_result = perform_full_gap_analysis(
            rfp_criteria_file="data/outputs/criteria_with_weights.json",
            company_profile_file="data/outputs/company_profile.json",
            output_file="data/outputs/gap_analysis.json"
        )
        
        # Load questions
        st.session_state.questions = gap_result.get('clarification_questions', [])
        st.session_state.processing_done = True
        
        st.success(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(st.session_state.questions)} Ø³Ø¤Ø§Ù„")
        
        return True
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£: {str(e)}")
        return False


# ============================================
# PAGE 2: Chatbot (ChatGPT Style)
# ============================================
def page_chatbot():
    st.title("ğŸ’¬ Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø§Ù‚ØµØ©")
    
    # Check if there are questions
    if not st.session_state.questions:
        st.success("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ ÙØ¬ÙˆØ§Øª - Ø§Ù„Ø´Ø±ÙƒØ© ØªÙ„Ø¨ÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª!")
        
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button("Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶ â¬…ï¸", use_container_width=True, type="primary"):
                st.session_state.page = 3
                st.rerun()
        return
    
    # Progress bar at top
    total_questions = len(st.session_state.questions)
    current_index = st.session_state.current_question_index
    progress = current_index / total_questions if not st.session_state.additional_info_asked else 1.0
    
    st.progress(progress)
    st.caption(f"ğŸ“Š Ø§Ù„Ø³Ø¤Ø§Ù„ {current_index} Ù…Ù† {total_questions}")
    st.markdown("---")
    
    # Add first question to history if not added yet
    if not st.session_state.first_question_added and current_index == 0 and total_questions > 0:
        st.session_state.chat_history.append({
            'type': 'question',
            'index': 0,
            'content': st.session_state.questions[0]
        })
        st.session_state.first_question_added = True
    
    # Chat container with custom CSS
    st.markdown("""
    <style>
    .ai-message {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 15px;
        margin: 10px 0;
        margin-left: 20%;
        text-align: right;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 15px;
        border-radius: 15px;
        margin: 10px 0;
        margin-right: 20%;
        text-align: right;
    }
    .message-label {
        font-weight: bold;
        margin-bottom: 5px;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Chat history display
    chat_container = st.container()
    with chat_container:
        # Display all previous messages
        for entry in st.session_state.chat_history:
            if entry['type'] == 'question':
                st.markdown(f"""
                <div class="ai-message">
                    <div class="message-label">ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ - Ø§Ù„Ø³Ø¤Ø§Ù„ {entry['index'] + 1}</div>
                    <div>{entry['content']}</div>
                </div>
                """, unsafe_allow_html=True)
            elif entry['type'] == 'answer':
                st.markdown(f"""
                <div class="user-message">
                    <div class="message-label">ğŸ‘¤ Ø£Ù†Øª</div>
                    <div>{entry['content']}</div>
                </div>
                """, unsafe_allow_html=True)
            elif entry['type'] == 'user_message':
                st.markdown(f"""
                <div class="user-message">
                    <div class="message-label">ğŸ‘¤ Ø£Ù†Øª</div>
                    <div>{entry['content']}</div>
                </div>
                """, unsafe_allow_html=True)
            elif entry['type'] == 'ai_response':
                st.markdown(f"""
                <div class="ai-message">
                    <div class="message-label">ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯</div>
                    <div>{entry['content']}</div>
                </div>
                """, unsafe_allow_html=True)
        
        # Show additional info question if all questions answered
        if not st.session_state.additional_info_asked and current_index >= total_questions:
            st.markdown(f"""
            <div class="ai-message">
                <div class="message-label">ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯</div>
                <div>Ù‡Ù„ ØªÙˆØ¯ Ø¥Ø¶Ø§ÙØ© Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¹Ø±Ø¶ØŸ</div>
                <div style="margin-top:10px; font-size:0.9em; color:#666;">
                (Ù…Ø«Ù„: Ø´Ù‡Ø§Ø¯Ø§ØªØŒ Ø¬ÙˆØ§Ø¦Ø²ØŒ Ù…Ø´Ø§Ø±ÙŠØ¹ Ø³Ø§Ø¨Ù‚Ø©ØŒ Ù…ÙŠØ²Ø§Øª ØªÙ†Ø§ÙØ³ÙŠØ©)
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Input area at bottom (ChatGPT style with conversational AI)
    if not st.session_state.additional_info_asked:
        if current_index < total_questions:
            # Initialize chatbot for current question if not initialized
            if st.session_state.conversation_model is None:
                from langchain_openai import ChatOpenAI
                st.session_state.conversation_model = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
                
                # Initialize conversation with system prompt
                system_msg = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„Ù„Ø¹Ø·Ø§Ø¡Ø§Øª ÙˆØ§Ù„Ù…Ù†Ø§Ù‚ØµØ§Øª.

Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ ({current_index + 1} Ù…Ù† {total_questions}):
{st.session_state.questions[current_index]}

Ù…Ù‡Ù…ØªÙƒ:
1. Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø³ØªÙØ³Ø§Ø±Ø§Ù‹ Ø£Ùˆ Ø·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­ - Ø£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡ Ø¨ÙˆØ¶ÙˆØ­ ÙˆÙ…Ù‡Ù†ÙŠØ§Ù‹
2. Ø¥Ø°Ø§ Ø£Ø¹Ø·Ø§Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø³Ø¤Ø§Ù„ - Ù‚Ù„ "âœ… Ø´ÙƒØ±Ø§Ù‹ØŒ ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ. Ø³Ù†Ù†ØªÙ‚Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ"
3. ÙƒÙ† Ù…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆØ±Ø³Ù…ÙŠØ§Ù‹
4. Ø³Ø§Ø¹Ø¯Ù‡ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ø°Ø§ Ø§Ø­ØªØ§Ø¬
5. Ù„Ø§ ØªÙ†ØªÙ‚Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ù†ÙØ³Ùƒ - ÙÙ‚Ø· Ø³Ø§Ø¹Ø¯Ù‡ Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ

Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù‡Ù…Ø©:
- Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙƒØ§Ù…Ù„Ø©ØŒ Ø£ÙƒØ¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: "âœ… Ø´ÙƒØ±Ø§Ù‹ØŒ ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ"
- Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù†Ø§Ù‚ØµØ©ØŒ Ø§Ø·Ù„Ø¨ Ø§Ù„ØªÙˆØ¶ÙŠØ­
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø³Ø¤Ø§Ù„ Ø§Ø³ØªÙØ³Ø§Ø±ÙŠØŒ Ø£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡ Ø¨ÙˆØ¶ÙˆØ­
"""
                st.session_state.conversation_history = [
                    {"role": "system", "content": system_msg}
                ]
            
            # Regular question input with AI conversation
            col1, col2 = st.columns([5, 1])
            
            # Use session state to control input value
            if f'input_value_{current_index}' not in st.session_state:
                st.session_state[f'input_value_{current_index}'] = ''
            
            with col1:
                user_input = st.text_area(
                    "",
                    value=st.session_state[f'input_value_{current_index}'],
                    key=f"chat_input_{current_index}",
                    height=100,
                    placeholder="Ø§ÙƒØªØ¨ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø£Ùˆ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ù‡Ù†Ø§...",
                    label_visibility="collapsed"
                )
            with col2:
                st.write("")  # spacing
                st.write("")  # spacing
                send_button = st.button("Ø¥Ø±Ø³Ø§Ù„ â¬†ï¸", use_container_width=True, type="primary")
            
            if send_button and user_input.strip():
                # Clear input box
                st.session_state[f'input_value_{current_index}'] = ''
                
                # Add user message to chat history display
                st.session_state.chat_history.append({
                    'type': 'user_message',
                    'index': current_index,
                    'content': user_input
                })
                
                # Get AI response
                st.session_state.conversation_history.append({
                    "role": "user",
                    "content": user_input
                })
                
                messages = [
                    {"role": msg["role"], "content": msg["content"]} 
                    for msg in st.session_state.conversation_history
                ]
                response = st.session_state.conversation_model.invoke(messages)
                ai_message = response.content
                
                st.session_state.conversation_history.append({
                    "role": "assistant",
                    "content": ai_message
                })
                
                # Add AI response to chat history display
                st.session_state.chat_history.append({
                    'type': 'ai_response',
                    'index': current_index,
                    'content': ai_message
                })
                
                # Check if answer is confirmed
                if "âœ…" in ai_message and "ØªÙ… ØªØ³Ø¬ÙŠÙ„" in ai_message:
                    # Save the actual answer (the user's last substantive message)
                    # Find the last user message that looks like an answer
                    user_messages = [
                        msg['content'] for msg in st.session_state.conversation_history 
                        if msg['role'] == 'user'
                    ]
                    
                    if user_messages:
                        st.session_state.answers[current_index] = {
                            'question': st.session_state.questions[current_index],
                            'answer': user_messages[-1],  # Last user message
                            'full_conversation': st.session_state.conversation_history.copy()
                        }
                    
                    # Reset for next question
                    st.session_state.current_question_index += 1
                    st.session_state.conversation_model = None
                    st.session_state.conversation_history = []
                    
                    # Add next question to history if available
                    if st.session_state.current_question_index < total_questions:
                        st.session_state.chat_history.append({
                            'type': 'question',
                            'index': st.session_state.current_question_index,
                            'content': st.session_state.questions[st.session_state.current_question_index]
                        })
                
                st.rerun()
        
        else:
            # Additional info input
            col1, col2 = st.columns([5, 1])
            with col1:
                additional_input = st.text_area(
                    "",
                    key="additional_info_input",
                    height=100,
                    placeholder="Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ø£Ùˆ Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ ÙˆØ§Ø¶ØºØ· Ø¥Ø±Ø³Ø§Ù„...",
                    label_visibility="collapsed"
                )
            with col2:
                st.write("")  # spacing
                st.write("")  # spacing
                finish_button = st.button("Ø¥Ø±Ø³Ø§Ù„ â¬†ï¸", use_container_width=True, type="primary")
            
            if finish_button:
                st.session_state.additional_info = additional_input if additional_input.strip() else None
                st.session_state.additional_info_asked = True
                
                # Add to chat history
                if additional_input.strip():
                    st.session_state.chat_history.append({
                        'type': 'answer',
                        'index': -1,
                        'content': additional_input
                    })
                else:
                    st.session_state.chat_history.append({
                        'type': 'answer',
                        'index': -1,
                        'content': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©"
                    })
                
                # Save chat history
                save_chat_history()
                
                st.rerun()
    
    else:
        # All done - show summary and next button
        st.success("âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª!")
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", len(st.session_state.answers))
            if st.session_state.additional_info:
                st.info("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©")
            
            st.markdown("<br>", unsafe_allow_html=True)
            
            if st.button("Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶ â¬…ï¸", use_container_width=True, type="primary"):
                st.session_state.page = 3
                st.rerun()


# ============================================
# Save Chat History
# ============================================
def save_chat_history():
    """Save complete chat session to file"""
    session_data = {
        "timestamp": datetime.now().isoformat(),
        "total_questions": len(st.session_state.questions),
        "questions": st.session_state.questions,
        "answers": st.session_state.answers,
        "chat_history": st.session_state.chat_history,
        "additional_info": st.session_state.additional_info
    }
    
    os.makedirs("data/outputs", exist_ok=True)
    with open("data/outputs/chat_history.json", 'w', encoding='utf-8') as f:
        json.dump(session_data, f, ensure_ascii=False, indent=2)


# ============================================
# PAGE 3: Generate Proposal (Placeholder)
# ============================================
def page_proposal():
    st.title("ğŸ“„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶")
    st.markdown("---")
    
    st.info("ğŸš§ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø© Ù‚ÙŠØ¯ Ø§Ù„ØªØ·ÙˆÙŠØ±...")
    
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        if st.button("â¬…ï¸ Ø§Ù„Ø¹ÙˆØ¯Ø©", use_container_width=True):
            st.session_state.page = 2
            st.rerun()


# ============================================
# Main App Logic
# ============================================
def main():
    # Sidebar
    st.sidebar.title("ğŸ“„ RFP Proposal Generator")
    st.sidebar.markdown("---")
    
    # Show current page
    page_names = {
        1: "1ï¸âƒ£ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª",
        2: "2ï¸âƒ£ Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª",
        3: "3ï¸âƒ£ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶"
    }
    
    st.sidebar.write(f"**Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:**")
    st.sidebar.write(f"### {page_names[st.session_state.page]}")
    
    st.sidebar.markdown("---")
    
    # Status indicators
    st.sidebar.write("**Ø§Ù„Ø­Ø§Ù„Ø©:**")
    if st.session_state.rfp_uploaded:
        st.sidebar.success("âœ… RFP Ù…Ø±ÙÙˆØ¹")
    else:
        st.sidebar.warning("â³ RFP ØºÙŠØ± Ù…Ø±ÙÙˆØ¹")
    
    if st.session_state.company_uploaded:
        st.sidebar.success("âœ… Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø±ÙÙˆØ¹")
    else:
        st.sidebar.warning("â³ Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ© ØºÙŠØ± Ù…Ø±ÙÙˆØ¹")
    
    if st.session_state.processing_done:
        st.sidebar.success(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(st.session_state.questions)} Ø³Ø¤Ø§Ù„")
    
    if st.session_state.additional_info_asked:
        st.sidebar.success("âœ… ØªÙ… Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª")
    
    # Route to correct page
    if st.session_state.page == 1:
        page_upload()
    elif st.session_state.page == 2:
        page_chatbot()
    elif st.session_state.page == 3:
        page_proposal()


# ============================================
# Run App
# ============================================
if __name__ == "__main__":
    main()