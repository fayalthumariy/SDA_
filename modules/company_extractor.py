"""
Company Profile Extractor Module
Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ù ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ù† PDF
"""

import re
import json
import os
from openai import OpenAI
import pdfplumber


def _read_pdf_text(pdf_path: str) -> str:
    """
    Extract text from PDF using multiple methods.
    Priority: pdfplumber -> pytesseract OCR
    """
    text = ""

    # Try pdfplumber first
    try:
        pages = []
        with pdfplumber.open(pdf_path) as pdf:
            for p in pdf.pages:
                t = p.extract_text() or ""
                pages.append(t)
        text = "\n".join(pages).strip()
        if text:
            print(f"âœ“ ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pdfplumber ({len(text)} Ø­Ø±Ù)")
            return text
    except Exception as e:
        print(f"ÙØ´Ù„ ÙÙŠ pdfplumber: {e}")

    # Fallback to OCR with pytesseract
    if not text:
        try:
            import pytesseract
            from pdf2image import convert_from_path
            print("Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ù€ OCR...")
            pages = convert_from_path(pdf_path, dpi=300)
            ocr_texts = []
            for i, page in enumerate(pages, 1):
                print(f"  OCR ØµÙØ­Ø© {i}/{len(pages)}...")
                page_text = pytesseract.image_to_string(page, lang='ara+eng')
                ocr_texts.append(page_text)
            text = "\n".join(ocr_texts).strip()
            if text:
                print(f"âœ“ ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR ({len(text)} Ø­Ø±Ù)")
        except Exception as e:
            print(f"ÙØ´Ù„ ÙÙŠ OCR: {e}")

    return text


def _basic_clean(s: str) -> str:
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬"""
    s = s.replace("\x00", " ")
    s = s.replace("\ufeff", "")  # Remove BOM
    # Collapse excessive whitespace
    s = re.sub(r"[ \t]+", " ", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def extract_company_profile_from_pdf(
    pdf_path: str,
    api_key: str = None,
    model: str = "gpt-4o-mini",
    max_ctx_chars: int = 20000,
    return_dict: bool = True,
    output_file: str = "company_profile.json"
):
    """
    Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù PDF Ù„Ù„Ø´Ø±ÙƒØ© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªØ¹Ø±ÙŠÙÙŠ

    Args:
        pdf_path: Ù…Ø³Ø§Ø± Ù…Ù„Ù PDF
        api_key: Ù…ÙØªØ§Ø­ OpenAI API
        model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        max_ctx_chars: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø£Ø­Ø±Ù
        return_dict: Ø¥Ø±Ø¬Ø§Ø¹ ÙƒÙ€ dict Ø£Ù… JSON string
        output_file: Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø­ÙØ¸

    Returns:
        Dict Ø£Ùˆ JSON string Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ©
    """
    
    # Initialize OpenAI client
    if api_key:
        llm_client = OpenAI(api_key=api_key)
    else:
        # Use from environment
        llm_client = OpenAI()

    # Extract text from PDF
    print(f"Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù PDF: {pdf_path}")
    full_text = _read_pdf_text(pdf_path)

    if not full_text:
        raise RuntimeError(f"Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù†Øµ Ù…Ù†: {pdf_path}")

    # Clean and truncate text
    full_text = _basic_clean(full_text)
    snippet = full_text[:max_ctx_chars]

    print(f"Ø¥Ø±Ø³Ø§Ù„ {len(snippet)} Ø­Ø±Ù Ø¥Ù„Ù‰ LLM (model: {model})...")

    prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ù„ÙØ§Øª ØªØ¹Ø±ÙŠÙ Ø´Ø±ÙƒØ§Øª.

Ø£ÙØ¹Ø·ÙŠØª Ù†ØµØ§Ù‹ Ø®Ø§Ù…Ø§Ù‹ Ù…ÙØ³ØªØ®Ø±Ø¬Ø§Ù‹ Ù…Ù† Ù…Ù„Ù PDF Ù„Ù„ØªØ¹Ø±ÙŠÙ Ø¨Ø§Ù„Ø´Ø±ÙƒØ© (Ù‚Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©).
Ø§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø­Ø±ÙÙŠØ§Ù‹ ÙÙŠ Ø§Ù„Ù†Øµ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø§Ø®ØªØ±Ø§Ø¹ Ø£Ùˆ ØªÙ„Ø®ÙŠØµ.

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:
- Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙÙ‚Ø·.
- Ø¥Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·.
- Ø¥Ø³ØªØ®Ø±Ø¬ Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø¥Ø¬ØªÙ…Ø§Ø¹ÙŠ Ùˆ Ø§Ù„Ø³ÙˆØ´Ù„ Ù…ÙŠØ¯ÙŠØ§ Ùˆ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ùˆ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ.
- Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ± Ø§ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø§Ùˆ Ù„Ù… ØªÙƒÙ† Ù…ØªÙˆØ§Ø¬Ø¯Ø© Ø§ÙƒØªØ¨ Ù„Ø§ ØªÙˆØ¬Ø¯.
- Ø§ÙƒØªØ¨ ÙÙ‚Ø· Ù…Ø§ Ù‡Ùˆ Ù…Ø°ÙƒÙˆØ± Ù†ØµØ§Ù‹.
- Ù„Ø§ ØªØ¶Ù Ø£Ùˆ ØªØªØ®ÙŠÙ„ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø©.
- Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø©ØŒ Ø£Ø¹Ø¯Ù‡Ø§ ÙƒÙ‚ÙŠÙ…Ø© ÙØ§Ø±ØºØ© "" Ø£Ùˆ Ù‚Ø§Ø¦Ù…Ø© [].
- Ø£Ø¹Ø¯ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… ÙƒÙ…Ø§ Ù‡ÙŠ (Ø®Ø¯Ù…Ø§ØªØŒ Ù…Ø¬Ø§Ù„Ø§ØªØŒ Ø£Ù‡Ø¯Ø§Ù...).
- Ø£Ø¹Ø¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ ØµÙŠØºØ© JSON ÙÙ‚Ø· ÙˆÙÙ‚ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠ:

{{
  "company_names": {{
    "ar": ["Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"],
    "en": ["Company name in English"]
  }},

  "previous_work": ["Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ© 1", "Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø´Ø±ÙƒØ© 1" , "Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ© 2", "Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø´Ø±ÙƒØ© 2", "Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ© 3", "Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø´Ø±ÙƒØ© 3" ],
  "about_us": " Ù†Ø¨Ø°Ø© Ø¹Ù† Ø§Ù„Ø´Ø±ÙƒØ© ÙƒÙ…Ø§ ÙˆØ±Ø¯ ÙÙŠ Ø§Ù„Ù†Øµ.",
  "description": "ÙˆØµÙ Ø§Ù„Ø´Ø±ÙƒØ© ÙƒÙ…Ø§ ÙˆØ±Ø¯ ÙÙŠ Ø§Ù„Ù†Øµ.",
  "services": ["Ø®Ø¯Ù…Ø© 1", "Ø®Ø¯Ù…Ø© 2"],
  "industries_or_focus": ["Ù…Ø¬Ø§Ù„ 1", "Ù…Ø¬Ø§Ù„ 2"],
  "values_or_objectives": ["Ù‚ÙŠÙ…Ø© 1", "Ù‡Ø¯Ù 1"],
  "licenses_or_certifications": ["ØªØ±Ø®ÙŠØµ 1", "Ø´Ù‡Ø§Ø¯Ø© 1"],
  "locations": ["Ø¹Ù†ÙˆØ§Ù† Ù…ÙˆÙ‚Ø¹ 1", "Ø¹Ù†ÙˆØ§Ù† Ù…Ù‚Ø± Ø§Ù„Ø´Ø±ÙƒØ© 1"],
  "contact": {{
    "phones": ["+966..."],
    "emails": ["email@example.com"],
    "social": ["https://..."],
    "website": "https://..."
  }},
  "vision": "Ø±Ø¤ÙŠØ© Ø§Ù„Ø´Ø±ÙƒØ©",
  "mission": "Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø´Ø±ÙƒØ©",
  "goals": ["Ù‡Ø¯Ù 1", "Ù‡Ø¯Ù 2"],
  "values": ["Ù‚ÙŠÙ…Ø© 1", "Ù‚ÙŠÙ…Ø© 2"],
  "experience_years": "Ø¹Ø¯Ø¯ Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø®Ø¨Ø±Ø© Ø¥Ù† ÙˆØ¬Ø¯Øª Ø¥Ù† Ù„Ù… ØªÙˆØ¬Ø¯ Ù„Ø§ ØªØ°ÙƒØ±Ù‡Ø§",
  "established_year": "Ø³Ù†Ø© Ø§Ù„ØªØ£Ø³ÙŠØ³ Ø¥Ù† ÙˆØ¬Ø¯Øª",
  "additional_info": "Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù‡Ù…Ø©"
}}

Ø§Ù„Ù†Øµ (Ù…Ù† Ù…Ù„Ù PDF):
-----------------------------------
{snippet}
-----------------------------------

Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù€ JSON ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠ.
    """.strip()

    try:
        resp = llm_client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2500,
            temperature=0
        )
        out = resp.choices[0].message.content.strip()
        print("âœ“ ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ø±Ø¯ Ù…Ù† LLM")

    except Exception as e:
        raise RuntimeError(f"ÙØ´Ù„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ LLM API: {e}")

    # Remove markdown code fences if present
    if out.startswith("```"):
        out = re.sub(r"^```(?:json)?\s*", "", out)
        out = re.sub(r"\s*```$", "", out)

    if return_dict:
        try:
            result = json.loads(out)
            print("âœ“ ØªÙ… ØªØ­Ù„ÙŠÙ„ JSON Ø¨Ù†Ø¬Ø§Ø­")
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ù…Ù„Ù
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"âœ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ {output_file}")
            
            return result
            
        except json.JSONDecodeError as e:
            print(f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON: {e}")
            # Try to fix common JSON issues
            out_fixed = out.replace("\u201c", '"').replace("\u201d", '"')
            out_fixed = out_fixed.replace("\u2019", "'").replace("\u2018", "'")
            out_fixed = re.sub(r",(\s*[}\]])", r"\1", out_fixed)  # Remove trailing commas
            try:
                result = json.loads(out_fixed)
                print("âœ“ ØªÙ… ØªØ­Ù„ÙŠÙ„ JSON Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥ØµÙ„Ø§Ø­")
                
                # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ù…Ù„Ù
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"âœ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ {output_file}")
                
                return result
            except:
                print("Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù„ÙŠÙ„ JSON. Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù….")
                return {"raw_response": out, "error": "JSON parsing failed"}

    return out


# ============================================
# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù†Ø³Ù‚Ø©
# ============================================
def print_company_profile(company_data):
    """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ© Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø³Ù‚"""
    
    print("\n" + "="*50)
    print("Ù…Ù„Ù ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬")
    print("="*50)
    
    # Ø§Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´Ø±ÙƒØ©
    if "company_names" in company_data:
        print(f"\nğŸ¢ Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©:")
        if company_data["company_names"].get("ar"):
            print(f"   Ø§Ù„Ø¹Ø±Ø¨ÙŠ: {', '.join(company_data['company_names']['ar'])}")
        if company_data["company_names"].get("en"):
            print(f"   English: {', '.join(company_data['company_names']['en'])}")
    
    # Ù†Ø¨Ø°Ø© Ø¹Ù† Ø§Ù„Ø´Ø±ÙƒØ©
    if company_data.get("about_us"):
        print(f"\nğŸ“– Ù†Ø¨Ø°Ø© Ø¹Ù† Ø§Ù„Ø´Ø±ÙƒØ©:")
        print(f"   {company_data['about_us']}")
    
    # Ø§Ù„Ø®Ø¯Ù…Ø§Øª
    if company_data.get("services"):
        print(f"\nâš™ï¸ Ø§Ù„Ø®Ø¯Ù…Ø§Øª:")
        for service in company_data["services"]:
            print(f"   â€¢ {service}")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„
    if company_data.get("contact"):
        print(f"\nğŸ“ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„:")
        contact = company_data["contact"]
        if contact.get("phones"):
            print(f"   Ø§Ù„Ù‡ÙˆØ§ØªÙ: {', '.join(contact['phones'])}")
        if contact.get("emails"):
            print(f"   Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª: {', '.join(contact['emails'])}")
        if contact.get("website"):
            print(f"   Ø§Ù„Ù…ÙˆÙ‚Ø¹: {contact['website']}")
    
    print("\n" + "="*50)