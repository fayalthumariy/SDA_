"""
RFP Proposal Generator - Streamlit App
Multi-page application for RFP processing and proposal generation
"""

import streamlit as st
import os
import json
from datetime import datetime

# ============================================
# Setup
# ============================================
# Set page config
st.set_page_config(
    page_title="RFP Proposal Generator",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for beautiful design
st.markdown("""
<style>
    /* Main theme colors */
    :root {
        --primary-color: #2E7D32;
        --secondary-color: #1976D2;
        --accent-color: #FF6F00;
        --background-light: #F5F7FA;
        --text-dark: #1A1A1A;
        --border-radius: 15px;
    }
    
    /* Hide Streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* Main container styling */
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
    }
    
    /* Content block styling */
    .block-container {
        background: white;
        border-radius: 20px;
        padding: 3rem 2rem;
        box-shadow: 0 10px 40px rgba(0,0,0,0.1);
        max-width: 1400px;
        margin: 0 auto;
    }
    
    /* Sidebar styling */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem 1rem;
    }
    
    [data-testid="stSidebar"] .element-container {
        color: white !important;
    }
    
    [data-testid="stSidebar"] h1, 
    [data-testid="stSidebar"] h2, 
    [data-testid="stSidebar"] h3,
    [data-testid="stSidebar"] p {
        color: white !important;
    }
    
    /* Title styling */
    h1 {
        color: #1A1A1A;
        font-size: 2.5rem !important;
        font-weight: 700 !important;
        margin-bottom: 1.5rem !important;
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    h2 {
        color: #2E7D32;
        font-size: 1.8rem !important;
        font-weight: 600 !important;
        margin: 2rem 0 1rem 0 !important;
    }
    
    h3 {
        color: #1976D2;
        font-size: 1.4rem !important;
        font-weight: 600 !important;
    }
    
    /* Button styling */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 0.75rem 2rem;
        font-size: 1.1rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
    }
    
    .stButton > button:active {
        transform: translateY(0);
    }
    
    /* Disabled button */
    .stButton > button:disabled {
        background: #cccccc;
        box-shadow: none;
        cursor: not-allowed;
    }
    
    /* File uploader styling */
    [data-testid="stFileUploader"] {
        background: #F8F9FA;
        border: 2px dashed #667eea;
        border-radius: 15px;
        padding: 2rem;
        transition: all 0.3s ease;
    }
    
    [data-testid="stFileUploader"]:hover {
        border-color: #764ba2;
        background: #F0F4FF;
    }
    
    /* Success/Warning/Error boxes */
    .stSuccess {
        background: linear-gradient(135deg, #00C9A7 0%, #00B894 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
        border: none;
    }
    
    .stWarning {
        background: linear-gradient(135deg, #FFB900 0%, #FF8C00 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
        border: none;
    }
    
    .stError {
        background: linear-gradient(135deg, #FF6B6B 0%, #EE5A6F 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
        border: none;
    }
    
    .stInfo {
        background: linear-gradient(135deg, #4FC3F7 0%, #29B6F6 100%);
        color: white;
        border-radius: 12px;
        padding: 1rem;
        border: none;
    }
    
    /* Progress bar */
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
    }
    
    /* Chat message bubbles */
    .ai-message {
        background: linear-gradient(135deg, #E8EAF6 0%, #C5CAE9 100%);
        padding: 1.2rem;
        border-radius: 18px 18px 18px 4px;
        margin: 1rem 0;
        margin-left: 10%;
        text-align: right;
        box-shadow: 0 2px 10px rgba(0,0,0,0.08);
        animation: slideIn 0.3s ease;
    }
    
    .user-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.2rem;
        border-radius: 18px 18px 4px 18px;
        margin: 1rem 0;
        margin-right: 10%;
        text-align: right;
        box-shadow: 0 2px 10px rgba(102, 126, 234, 0.3);
        animation: slideIn 0.3s ease;
    }
    
    .message-label {
        font-weight: 700;
        font-size: 0.9rem;
        margin-bottom: 0.5rem;
        opacity: 0.9;
    }
    
    @keyframes slideIn {
        from {
            opacity: 0;
            transform: translateY(10px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    /* Text input/textarea */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea {
        border-radius: 12px;
        border: 2px solid #E0E0E0;
        padding: 0.75rem;
        font-size: 1rem;
        transition: all 0.3s ease;
    }
    
    .stTextInput > div > div > input:focus,
    .stTextArea > div > div > textarea:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    /* Metrics */
    [data-testid="stMetric"] {
        background: linear-gradient(135deg, #F8F9FA 0%, #E9ECEF 100%);
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    }
    
    [data-testid="stMetric"] label {
        font-size: 1rem !important;
        color: #666 !important;
        font-weight: 600 !important;
    }
    
    [data-testid="stMetric"] [data-testid="stMetricValue"] {
        font-size: 1.8rem !important;
        font-weight: 700 !important;
        color: #667eea !important;
    }
    
    /* Divider */
    hr {
        margin: 2rem 0;
        border: none;
        height: 2px;
        background: linear-gradient(90deg, transparent, #667eea, transparent);
    }
    
    /* Expander */
    .streamlit-expanderHeader {
        background: linear-gradient(135deg, #F8F9FA 0%, #E9ECEF 100%);
        border-radius: 12px;
        padding: 1rem;
        font-weight: 600;
    }
    
    /* Download button */
    .stDownloadButton > button {
        background: linear-gradient(135deg, #00C9A7 0%, #00B894 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        box-shadow: 0 4px 15px rgba(0, 201, 167, 0.4);
    }
    
    .stDownloadButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(0, 201, 167, 0.6);
    }
    
    /* Spinner */
    .stSpinner > div {
        border-top-color: #667eea !important;
    }
    
    /* Columns */
    [data-testid="column"] {
        padding: 0.5rem;
    }
    
    /* Caption */
    .caption {
        color: #666;
        font-size: 0.9rem;
        margin-top: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

import streamlit as st
os.environ["OPENAI_API_KEY"] = st.secrets("OPENAI_API_KEY")

# ============================================
# Session State Initialization
# ============================================
if 'page' not in st.session_state:
    st.session_state.page = 1

if 'rfp_uploaded' not in st.session_state:
    st.session_state.rfp_uploaded = False

if 'company_uploaded' not in st.session_state:
    st.session_state.company_uploaded = False

if 'processing_done' not in st.session_state:
    st.session_state.processing_done = False

if 'questions' not in st.session_state:
    st.session_state.questions = []

if 'current_question_index' not in st.session_state:
    st.session_state.current_question_index = 0

if 'answers' not in st.session_state:
    st.session_state.answers = {}

if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

if 'first_question_added' not in st.session_state:
    st.session_state.first_question_added = False

if 'additional_info_asked' not in st.session_state:
    st.session_state.additional_info_asked = False

if 'conversation_model' not in st.session_state:
    st.session_state.conversation_model = None

if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []

if 'waiting_for_answer' not in st.session_state:
    st.session_state.waiting_for_answer = True

if 'current_answer_collected' not in st.session_state:
    st.session_state.current_answer_collected = False


# ============================================
# PAGE 1: Upload Files
# ============================================
def page_upload():
    # Animated title with icon
    st.markdown("""
    <div style='text-align: center; padding: 2rem 0;'>
        <h1 style='font-size: 3rem; margin-bottom: 0.5rem;'>
            ğŸ“„ Ù…ÙˆÙ„Ù‘Ø¯ Ø§Ù„Ø¹Ø±ÙˆØ¶ Ø§Ù„ÙÙ†ÙŠØ© Ù„Ù„Ù…Ù†Ø§Ù‚ØµØ§Øª
        </h1>
        <p style='font-size: 1.2rem; color: #666; font-weight: 500;'>
            RFP Proposal Generator - Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ø±ÙˆØ¶ Ø§Ø­ØªØ±Ø§ÙÙŠØ©
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    st.markdown("""
    <div style='background: linear-gradient(135deg, #E8EAF6 0%, #C5CAE9 100%); 
                padding: 1.5rem; border-radius: 15px; margin-bottom: 2rem;'>
        <h3 style='color: #5E35B1; margin: 0;'>ğŸ“‹ Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª</h3>
        <p style='color: #666; margin-top: 0.5rem;'>
            Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª RFP ÙˆØ§Ù„Ø´Ø±ÙƒØ© Ù„Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2, gap="large")
    
    with col1:
        st.markdown("""
        <div style='background: white; padding: 1.5rem; border-radius: 15px; 
                    border: 2px solid #E8EAF6; margin-bottom: 1rem;'>
            <h3 style='color: #5E35B1; margin: 0; display: flex; align-items: center;'>
                ğŸ“‹ <span style='margin-right: 0.5rem;'>Ù…Ù„Ù RFP</span>
            </h3>
        </div>
        """, unsafe_allow_html=True)
        
        rfp_file = st.file_uploader(
            "Ø§Ø±ÙØ¹ Ù…Ù„Ù RFP (PDF)",
            type=['pdf'],
            key='rfp_uploader',
            help="Ù…Ù„Ù ÙƒØ±Ø§Ø³Ø© Ø§Ù„Ø´Ø±ÙˆØ· ÙˆØ§Ù„Ù…ÙˆØ§ØµÙØ§Øª"
        )
        
        if rfp_file:
            # Save file
            os.makedirs("data/uploads", exist_ok=True)
            rfp_path = f"data/uploads/rfp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            with open(rfp_path, "wb") as f:
                f.write(rfp_file.getbuffer())
            
            st.session_state.rfp_uploaded = True
            st.session_state.rfp_path = rfp_path
            st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ù…Ù„Ù RFP: {rfp_file.name}")
    
    with col2:
        st.markdown("""
        <div style='background: white; padding: 1.5rem; border-radius: 15px; 
                    border: 2px solid #E8EAF6; margin-bottom: 1rem;'>
            <h3 style='color: #5E35B1; margin: 0; display: flex; align-items: center;'>
                ğŸ¢ <span style='margin-right: 0.5rem;'>Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ©</span>
            </h3>
        </div>
        """, unsafe_allow_html=True)
        
        company_file = st.file_uploader(
            "Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ø§Ù„Ø´Ø±ÙƒØ© (PDF)",
            type=['pdf'],
            key='company_uploader',
            help="Ù…Ù„Ù Ø§Ù„ØªØ¹Ø±ÙŠÙ Ø¨Ø§Ù„Ø´Ø±ÙƒØ© ÙˆÙ‚Ø¯Ø±Ø§ØªÙ‡Ø§"
        )
        
        if company_file:
            # Save file
            os.makedirs("data/uploads", exist_ok=True)
            company_path = f"data/uploads/company_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            with open(company_path, "wb") as f:
                f.write(company_file.getbuffer())
            
            st.session_state.company_uploaded = True
            st.session_state.company_path = company_path
            st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ©: {company_file.name}")
    
    st.markdown("---")
    
    # Status
    if st.session_state.rfp_uploaded and st.session_state.company_uploaded:
        st.success("âœ… ØªÙ… Ø±ÙØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©!")
    else:
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ ÙƒÙ„Ø§ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©")
    
    # Next button
    st.markdown("<br>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        next_disabled = not (st.session_state.rfp_uploaded and st.session_state.company_uploaded)
        
        button_html = f"""
        <div style='text-align: center; margin: 2rem 0;'>
            {'<p style="color: #999; font-size: 0.9rem; margin-bottom: 1rem;">âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ ÙƒÙ„Ø§ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©</p>' if next_disabled else ''}
        </div>
        """
        st.markdown(button_html, unsafe_allow_html=True)
        
        if st.button(
            "ğŸš€ Ø§Ù„ØªØ§Ù„ÙŠ: ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª",
            disabled=next_disabled,
            use_container_width=True,
            type="primary"
        ):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª..."):
                # Process files
                success = process_files()
                
                if success:
                    st.session_state.page = 2
                    st.rerun()
                else:
                    st.error("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª")


# ============================================
# Initialize Conversational AI
# ============================================
def initialize_chatbot(current_question, question_index, total_questions):
    """Initialize conversational chatbot for current question"""
    from langchain_openai import ChatOpenAI
    
    model = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
    
    system_prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„Ù„Ø¹Ø·Ø§Ø¡Ø§Øª ÙˆØ§Ù„Ù…Ù†Ø§Ù‚ØµØ§Øª.

Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ ({question_index + 1} Ù…Ù† {total_questions}):
{current_question}

Ù…Ù‡Ù…ØªÙƒ:
1. Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø³ØªÙØ³Ø§Ø±Ø§Ù‹ Ø£Ùˆ Ø·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­ - Ø£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡ Ø¨ÙˆØ¶ÙˆØ­
2. Ø¥Ø°Ø§ Ø£Ø¹Ø·Ø§Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ§Ù…Ù„Ø© - Ù‚Ù„ Ù„Ù‡ "Ø´ÙƒØ±Ø§Ù‹ØŒ ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ" 
3. ÙƒÙ† Ù…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆØ±Ø³Ù…ÙŠØ§Ù‹
4. Ø³Ø§Ø¹Ø¯Ù‡ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ø°Ø§ Ø§Ø­ØªØ§Ø¬
5. Ù„Ø§ ØªÙ†ØªÙ‚Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ - ÙÙ‚Ø· Ø³Ø§Ø¹Ø¯Ù‡ Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ

Ø¹Ù†Ø¯ ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø¨Ø§Ø±Ø© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©: "âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ"
"""
    
    return model, system_prompt


def get_ai_response(user_message, model, conversation_history):
    """Get AI response for user message"""
    
    # Add user message to history
    conversation_history.append({"role": "user", "content": user_message})
    
    # Get AI response
    messages = [{"role": msg["role"], "content": msg["content"]} for msg in conversation_history]
    response = model.invoke(messages)
    ai_message = response.content
    
    # Add AI response to history
    conversation_history.append({"role": "assistant", "content": ai_message})
    
    return ai_message, conversation_history


def is_answer_confirmed(ai_message):
    """Check if AI confirmed the answer"""
    confirmation_phrases = [
        "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ",
        "âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„",
        "Ø´ÙƒØ±Ø§Ù‹ØŒ ØªÙ… ØªØ³Ø¬ÙŠÙ„"
    ]
    return any(phrase in ai_message for phrase in confirmation_phrases)


# ============================================
# File Processing Function
# ============================================
def process_files():
    """Process uploaded files and extract questions"""
    try:
        from modules.rfp_extractor import extract_and_weight_rfp_criteria
        from modules.company_extractor import extract_company_profile_from_pdf
        from modules.gap_analyzer import perform_full_gap_analysis
        
        # Step 1: Extract RFP
        st.write("ğŸ“‹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø§ÙŠÙŠØ± RFP...")
        rfp_result = extract_and_weight_rfp_criteria(
            pdf_path=st.session_state.rfp_path,
            output_file="data/outputs/criteria_with_weights.json"
        )
        
        # Step 2: Extract Company Profile
        st.write("ğŸ¢ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø±ÙˆÙØ§ÙŠÙ„ Ø§Ù„Ø´Ø±ÙƒØ©...")
        company_result = extract_company_profile_from_pdf(
            pdf_path=st.session_state.company_path,
            output_file="data/outputs/company_profile.json"
        )
        
        # Step 3: Gap Analysis
        st.write("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª...")
        gap_result = perform_full_gap_analysis(
            rfp_criteria_file="data/outputs/criteria_with_weights.json",
            company_profile_file="data/outputs/company_profile.json",
            output_file="data/outputs/gap_analysis.json"
        )
        
        # Load questions
        st.session_state.questions = gap_result.get('clarification_questions', [])
        st.session_state.processing_done = True
        
        st.success(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(st.session_state.questions)} Ø³Ø¤Ø§Ù„")
        
        return True
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£: {str(e)}")
        return False


# ============================================
# PAGE 2: Chatbot (ChatGPT Style)
# ============================================
def page_chatbot():
    st.markdown("""
    <div style='text-align: center; padding: 1.5rem 0;'>
        <h1 style='font-size: 2.5rem; margin-bottom: 0.5rem;'>
            ğŸ’¬ Ù…Ø³Ø§Ø¹Ø¯ Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø°ÙƒÙŠ
        </h1>
        <p style='font-size: 1.1rem; color: #666;'>
            ØªÙØ§Ø¹Ù„ Ù…Ø¹Ù†Ø§ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø§Ù‚ØµØ©
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Check if there are questions
    if not st.session_state.questions:
        st.success("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ ÙØ¬ÙˆØ§Øª - Ø§Ù„Ø´Ø±ÙƒØ© ØªÙ„Ø¨ÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª!")
        
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button("Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶ â¬…ï¸", use_container_width=True, type="primary"):
                st.session_state.page = 3
                st.rerun()
        return
    
    # Progress bar at top
    total_questions = len(st.session_state.questions)
    current_index = st.session_state.current_question_index
    progress = current_index / total_questions if not st.session_state.additional_info_asked else 1.0
    
    st.progress(progress)
    st.caption(f"ğŸ“Š Ø§Ù„Ø³Ø¤Ø§Ù„ {current_index} Ù…Ù† {total_questions}")
    st.markdown("---")
    
    # Add first question to history if not added yet
    if not st.session_state.first_question_added and current_index == 0 and total_questions > 0:
        st.session_state.chat_history.append({
            'type': 'question',
            'index': 0,
            'content': st.session_state.questions[0]
        })
        st.session_state.first_question_added = True
    
    # Chat container with custom CSS
    st.markdown("""
    <style>
    .ai-message {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 15px;
        margin: 10px 0;
        margin-left: 20%;
        text-align: right;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 15px;
        border-radius: 15px;
        margin: 10px 0;
        margin-right: 20%;
        text-align: right;
    }
    .message-label {
        font-weight: bold;
        margin-bottom: 5px;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Chat history display
    chat_container = st.container()
    with chat_container:
        # Display all previous messages
        for entry in st.session_state.chat_history:
            if entry['type'] == 'question':
                st.markdown(f"""
                <div class="ai-message">
                    <div class="message-label">ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ - Ø§Ù„Ø³Ø¤Ø§Ù„ {entry['index'] + 1}</div>
                    <div>{entry['content']}</div>
                </div>
                """, unsafe_allow_html=True)
            elif entry['type'] == 'answer':
                st.markdown(f"""
                <div class="user-message">
                    <div class="message-label">ğŸ‘¤ Ø£Ù†Øª</div>
                    <div>{entry['content']}</div>
                </div>
                """, unsafe_allow_html=True)
            elif entry['type'] == 'user_message':
                st.markdown(f"""
                <div class="user-message">
                    <div class="message-label">ğŸ‘¤ Ø£Ù†Øª</div>
                    <div>{entry['content']}</div>
                </div>
                """, unsafe_allow_html=True)
            elif entry['type'] == 'ai_response':
                st.markdown(f"""
                <div class="ai-message">
                    <div class="message-label">ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯</div>
                    <div>{entry['content']}</div>
                </div>
                """, unsafe_allow_html=True)
        
        # Show additional info question if all questions answered
        if not st.session_state.additional_info_asked and current_index >= total_questions:
            st.markdown(f"""
            <div class="ai-message">
                <div class="message-label">ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯</div>
                <div>Ù‡Ù„ ØªÙˆØ¯ Ø¥Ø¶Ø§ÙØ© Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¹Ø±Ø¶ØŸ</div>
                <div style="margin-top:10px; font-size:0.9em; color:#666;">
                (Ù…Ø«Ù„: Ø´Ù‡Ø§Ø¯Ø§ØªØŒ Ø¬ÙˆØ§Ø¦Ø²ØŒ Ù…Ø´Ø§Ø±ÙŠØ¹ Ø³Ø§Ø¨Ù‚Ø©ØŒ Ù…ÙŠØ²Ø§Øª ØªÙ†Ø§ÙØ³ÙŠØ©)
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Input area at bottom (ChatGPT style with conversational AI)
    if not st.session_state.additional_info_asked:
        if current_index < total_questions:
            # Initialize chatbot for current question if not initialized
            if st.session_state.conversation_model is None:
                from langchain_openai import ChatOpenAI
                st.session_state.conversation_model = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
                
                # Initialize conversation with system prompt
                system_msg = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„Ù„Ø¹Ø·Ø§Ø¡Ø§Øª ÙˆØ§Ù„Ù…Ù†Ø§Ù‚ØµØ§Øª.

Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ ({current_index + 1} Ù…Ù† {total_questions}):
{st.session_state.questions[current_index]}

Ù…Ù‡Ù…ØªÙƒ:
1. Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø³ØªÙØ³Ø§Ø±Ø§Ù‹ Ø£Ùˆ Ø·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­ - Ø£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡ Ø¨ÙˆØ¶ÙˆØ­ ÙˆÙ…Ù‡Ù†ÙŠØ§Ù‹
2. Ø¥Ø°Ø§ Ø£Ø¹Ø·Ø§Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø³Ø¤Ø§Ù„ - Ù‚Ù„ "âœ… Ø´ÙƒØ±Ø§Ù‹ØŒ ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ. Ø³Ù†Ù†ØªÙ‚Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ"
3. ÙƒÙ† Ù…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆØ±Ø³Ù…ÙŠØ§Ù‹
4. Ø³Ø§Ø¹Ø¯Ù‡ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ø°Ø§ Ø§Ø­ØªØ§Ø¬
5. Ù„Ø§ ØªÙ†ØªÙ‚Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ù†ÙØ³Ùƒ - ÙÙ‚Ø· Ø³Ø§Ø¹Ø¯Ù‡ Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ

Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù‡Ù…Ø©:
- Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙƒØ§Ù…Ù„Ø©ØŒ Ø£ÙƒØ¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: "âœ… Ø´ÙƒØ±Ø§Ù‹ØŒ ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¥Ø¬Ø§Ø¨ØªÙƒ"
- Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù†Ø§Ù‚ØµØ©ØŒ Ø§Ø·Ù„Ø¨ Ø§Ù„ØªÙˆØ¶ÙŠØ­
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø³Ø¤Ø§Ù„ Ø§Ø³ØªÙØ³Ø§Ø±ÙŠØŒ Ø£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡ Ø¨ÙˆØ¶ÙˆØ­
"""
                st.session_state.conversation_history = [
                    {"role": "system", "content": system_msg}
                ]
            
            # Regular question input with AI conversation
            col1, col2 = st.columns([5, 1])
            
            # Use session state to control input value
            if f'input_value_{current_index}' not in st.session_state:
                st.session_state[f'input_value_{current_index}'] = ''
            
            with col1:
                user_input = st.text_area(
                    "",
                    value=st.session_state[f'input_value_{current_index}'],
                    key=f"chat_input_{current_index}",
                    height=100,
                    placeholder="Ø§ÙƒØªØ¨ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø£Ùˆ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ù‡Ù†Ø§...",
                    label_visibility="collapsed"
                )
            with col2:
                st.write("")  # spacing
                st.write("")  # spacing
                send_button = st.button("Ø¥Ø±Ø³Ø§Ù„ â¬†ï¸", use_container_width=True, type="primary")
            
            if send_button and user_input.strip():
                # Clear input box
                st.session_state[f'input_value_{current_index}'] = ''
                
                # Add user message to chat history display
                st.session_state.chat_history.append({
                    'type': 'user_message',
                    'index': current_index,
                    'content': user_input
                })
                
                # Get AI response
                st.session_state.conversation_history.append({
                    "role": "user",
                    "content": user_input
                })
                
                messages = [
                    {"role": msg["role"], "content": msg["content"]} 
                    for msg in st.session_state.conversation_history
                ]
                response = st.session_state.conversation_model.invoke(messages)
                ai_message = response.content
                
                st.session_state.conversation_history.append({
                    "role": "assistant",
                    "content": ai_message
                })
                
                # Add AI response to chat history display
                st.session_state.chat_history.append({
                    'type': 'ai_response',
                    'index': current_index,
                    'content': ai_message
                })
                
                # Check if answer is confirmed
                if "âœ…" in ai_message and "ØªÙ… ØªØ³Ø¬ÙŠÙ„" in ai_message:
                    # Save the actual answer (the user's last substantive message)
                    # Find the last user message that looks like an answer
                    user_messages = [
                        msg['content'] for msg in st.session_state.conversation_history 
                        if msg['role'] == 'user'
                    ]
                    
                    if user_messages:
                        st.session_state.answers[current_index] = {
                            'question': st.session_state.questions[current_index],
                            'answer': user_messages[-1],  # Last user message
                            'full_conversation': st.session_state.conversation_history.copy()
                        }
                    
                    # Reset for next question
                    st.session_state.current_question_index += 1
                    st.session_state.conversation_model = None
                    st.session_state.conversation_history = []
                    
                    # Add next question to history if available
                    if st.session_state.current_question_index < total_questions:
                        st.session_state.chat_history.append({
                            'type': 'question',
                            'index': st.session_state.current_question_index,
                            'content': st.session_state.questions[st.session_state.current_question_index]
                        })
                
                st.rerun()
        
        else:
            # Additional info input
            col1, col2 = st.columns([5, 1])
            with col1:
                additional_input = st.text_area(
                    "",
                    key="additional_info_input",
                    height=100,
                    placeholder="Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ø£Ùˆ Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ ÙˆØ§Ø¶ØºØ· Ø¥Ø±Ø³Ø§Ù„...",
                    label_visibility="collapsed"
                )
            with col2:
                st.write("")  # spacing
                st.write("")  # spacing
                finish_button = st.button("Ø¥Ø±Ø³Ø§Ù„ â¬†ï¸", use_container_width=True, type="primary")
            
            if finish_button:
                st.session_state.additional_info = additional_input if additional_input.strip() else None
                st.session_state.additional_info_asked = True
                
                # Add to chat history
                if additional_input.strip():
                    st.session_state.chat_history.append({
                        'type': 'answer',
                        'index': -1,
                        'content': additional_input
                    })
                else:
                    st.session_state.chat_history.append({
                        'type': 'answer',
                        'index': -1,
                        'content': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©"
                    })
                
                # Save chat history
                save_chat_history()
                
                st.rerun()
    
    else:
        # All done - show summary and next button
        st.success("âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª!")
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", len(st.session_state.answers))
            if st.session_state.additional_info:
                st.info("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©")
            
            st.markdown("<br>", unsafe_allow_html=True)
            
            if st.button("Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶ â¬…ï¸", use_container_width=True, type="primary"):
                st.session_state.page = 3
                st.rerun()


# ============================================
# Save Chat History
# ============================================
def save_chat_history():
    """Save complete chat session to file"""
    session_data = {
        "timestamp": datetime.now().isoformat(),
        "total_questions": len(st.session_state.questions),
        "questions": st.session_state.questions,
        "answers": st.session_state.answers,
        "chat_history": st.session_state.chat_history,
        "additional_info": st.session_state.additional_info
    }
    
    os.makedirs("data/outputs", exist_ok=True)
    with open("data/outputs/chat_history.json", 'w', encoding='utf-8') as f:
        json.dump(session_data, f, ensure_ascii=False, indent=2)


# ============================================
# PAGE 3: Generate Proposal
# ============================================
def page_proposal():
    st.markdown("""
    <div style='text-align: center; padding: 1.5rem 0;'>
        <h1 style='font-size: 2.5rem; margin-bottom: 0.5rem;'>
            ğŸ“„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙÙ†ÙŠ
        </h1>
        <p style='font-size: 1.1rem; color: #666;'>
            Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ø±Ø¶ ÙÙ†ÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        </p>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("---")
    
    # Check if previous steps are completed
    if not st.session_state.additional_info_asked:
        st.warning("âš ï¸ ÙŠØ¬Ø¨ Ø¥ÙƒÙ…Ø§Ù„ Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£ÙˆÙ„Ø§Ù‹")
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            if st.button("â¬…ï¸ Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", use_container_width=True):
                st.session_state.page = 2
                st.rerun()
        return
    
    st.success("âœ… ØªÙ… Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©!")
    
    st.markdown("---")
    
    # Summary of collected data
    st.subheader("ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Ù…Ø¹Ø§ÙŠÙŠØ± RFP", "âœ… Ø¬Ø§Ù‡Ø²")
    
    with col2:
        st.metric("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø±ÙƒØ©", "âœ… Ø¬Ø§Ù‡Ø²")
    
    with col3:
        answers_count = len(st.session_state.answers)
        st.metric("Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©", f"{answers_count} Ø³Ø¤Ø§Ù„")
    
    st.markdown("---")
    
    # Generation section
    st.subheader("ğŸš€ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶")
    
    st.info("""
    ğŸ’¡ **Ù…Ù„Ø§Ø­Ø¸Ø©:** Ø¹Ù…Ù„ÙŠØ© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶ Ù‚Ø¯ ØªØ³ØªØºØ±Ù‚ 2-5 Ø¯Ù‚Ø§Ø¦Ù‚ Ø­ÙŠØ« ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ù€:
    - ØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
    - ÙƒØªØ§Ø¨Ø© 16 Ù‚Ø³Ù… Ù…Ù† Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙÙ†ÙŠ
    - Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    """)
    
    # Check if proposal already generated
    proposal_md_exists = os.path.exists("data/outputs/proposal.md")
    proposal_pdf_exists = os.path.exists("data/outputs/proposal.pdf")
    
    if proposal_pdf_exists or proposal_md_exists:
        st.success("âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø¹Ø±Ø¶ Ø³Ø§Ø¨Ù‚Ø§Ù‹")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ”„ ØªÙˆÙ„ÙŠØ¯ Ø¹Ø±Ø¶ Ø¬Ø¯ÙŠØ¯", use_container_width=True, type="primary"):
                generate_proposal_workflow()
        
        with col2:
            # Prefer PDF if exists, otherwise MD
            if proposal_pdf_exists:
                with open("data/outputs/proposal.pdf", 'rb') as f:
                    pdf_content = f.read()
                
                st.download_button(
                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ (PDF)",
                    data=pdf_content,
                    file_name="proposal.pdf",
                    mime="application/pdf",
                    use_container_width=True
                )
            elif proposal_md_exists:
                with open("data/outputs/proposal.md", 'r', encoding='utf-8') as f:
                    md_content = f.read()
                
                st.download_button(
                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ (Markdown)",
                    data=md_content,
                    file_name="proposal.md",
                    mime="text/markdown",
                    use_container_width=True
                )
        
        # Show preview
        st.markdown("---")
        st.subheader("ğŸ‘ï¸ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¹Ø±Ø¶")
        
        # Read markdown for preview
        if proposal_md_exists:
            with open("data/outputs/proposal.md", 'r', encoding='utf-8') as f:
                proposal_content = f.read()
            
            with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰", expanded=False):
                st.markdown(proposal_content)
    
    else:
        # Generate new proposal
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            if st.button("ğŸ¯ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙÙ†ÙŠ", use_container_width=True, type="primary"):
                generate_proposal_workflow()


def generate_proposal_workflow():
    """Run the proposal generation workflow"""
    
    with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶... (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ 2-5 Ø¯Ù‚Ø§Ø¦Ù‚)"):
        try:
            # Progress indicators
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Import proposal generator
            status_text.text("ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙˆÙ„...")
            progress_bar.progress(10)
            
            from modules.proposal_generator import generate_proposal
            
            # Generate proposal (both MD and PDF)
            status_text.text("ğŸ¤– Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…...")
            progress_bar.progress(30)
            
            proposal = generate_proposal(
                rfp_criteria_file="data/outputs/criteria_with_weights.json",
                company_profile_file="data/outputs/company_profile.json",
                gap_analysis_file="data/outputs/gap_analysis.json",
                chat_history_file="data/outputs/chat_history.json",
                output_file="data/outputs/proposal.md",
                generate_pdf=True  # Generate PDF version
            )
            
            progress_bar.progress(100)
            status_text.text("âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶ Ø¨Ù†Ø¬Ø§Ø­!")
            
            st.success("ğŸ‰ ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙÙ†ÙŠ Ø¨Ù†Ø¬Ø§Ø­!")
            
            # Check if PDF was created
            pdf_exists = os.path.exists("data/outputs/proposal.pdf")
            
            if pdf_exists:
                # Offer PDF download
                with open("data/outputs/proposal.pdf", 'rb') as f:
                    pdf_content = f.read()
                
                st.download_button(
                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ (PDF)",
                    data=pdf_content,
                    file_name="proposal.pdf",
                    mime="application/pdf",
                    use_container_width=True
                )
            else:
                # Fallback to markdown
                st.download_button(
                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ (Markdown)",
                    data=proposal,
                    file_name="proposal.md",
                    mime="text/markdown",
                    use_container_width=True
                )
            
            # Show preview
            st.markdown("---")
            st.subheader("ğŸ‘ï¸ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¹Ø±Ø¶")
            
            with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰", expanded=True):
                st.markdown(proposal)
            
        except FileNotFoundError as e:
            st.error(f"âŒ Ø®Ø·Ø£: Ù…Ù„Ù Ù…ÙÙ‚ÙˆØ¯ - {e}")
            st.info("ğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† Ø¥ÙƒÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©")
            
        except Exception as e:
            st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
            with st.expander("ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£"):
                import traceback
                st.code(traceback.format_exc())


# ============================================
# Main App Logic
# ============================================
def main():
    # Sidebar
    with st.sidebar:
        st.markdown("""
        <div style='text-align: center; padding: 1rem 0; margin-bottom: 2rem;'>
            <h1 style='font-size: 2rem; color: white; margin: 0;'>
                ğŸ“„
            </h1>
            <h2 style='font-size: 1.3rem; color: white; margin: 0.5rem 0;'>
                RFP Generator
            </h2>
            <p style='color: rgba(255,255,255,0.8); font-size: 0.9rem; margin: 0;'>
                Ù…ÙˆÙ„Ù‘Ø¯ Ø§Ù„Ø¹Ø±ÙˆØ¶ Ø§Ù„Ø°ÙƒÙŠ
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Show current page
        page_names = {
            1: "ğŸ“¤ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª",
            2: "ğŸ’¬ Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª",
            3: "ğŸ“„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶"
        }
        
        st.markdown("""
        <div style='background: rgba(255,255,255,0.1); padding: 1rem; 
                    border-radius: 10px; margin-bottom: 1.5rem;'>
            <p style='color: rgba(255,255,255,0.8); font-size: 0.9rem; margin: 0;'>
                Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        for page_num, page_name in page_names.items():
            if page_num == st.session_state.page:
                st.markdown(f"""
                <div style='background: rgba(255,255,255,0.2); padding: 0.8rem; 
                            border-radius: 8px; margin-bottom: 0.5rem;'>
                    <p style='color: white; font-weight: 600; margin: 0; font-size: 1.1rem;'>
                        â–¶ {page_name}
                    </p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style='padding: 0.8rem; margin-bottom: 0.5rem;'>
                    <p style='color: rgba(255,255,255,0.6); margin: 0;'>
                        {page_name}
                    </p>
                </div>
                """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Status indicators
        st.markdown("""
        <div style='background: rgba(255,255,255,0.1); padding: 1rem; 
                    border-radius: 10px;'>
            <p style='color: rgba(255,255,255,0.8); font-size: 0.9rem; margin-bottom: 1rem;'>
                Ø­Ø§Ù„Ø© Ø§Ù„ØªÙ‚Ø¯Ù…:
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        status_items = []
        if st.session_state.rfp_uploaded:
            status_items.append(("âœ…", "RFP Ù…Ø±ÙÙˆØ¹", True))
        else:
            status_items.append(("â³", "RFP ØºÙŠØ± Ù…Ø±ÙÙˆØ¹", False))
        
        if st.session_state.company_uploaded:
            status_items.append(("âœ…", "Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ© Ù…Ø±ÙÙˆØ¹", True))
        else:
            status_items.append(("â³", "Ù…Ù„Ù Ø§Ù„Ø´Ø±ÙƒØ© ØºÙŠØ± Ù…Ø±ÙÙˆØ¹", False))
        
        if st.session_state.processing_done:
            questions_count = len(st.session_state.questions)
            status_items.append(("âœ…", f"ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {questions_count} Ø³Ø¤Ø§Ù„", True))
        
        if st.session_state.additional_info_asked:
            status_items.append(("âœ…", "ØªÙ… Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", True))
        
        for icon, text, is_complete in status_items:
            color = "rgba(76, 175, 80, 0.9)" if is_complete else "rgba(255,255,255,0.5)"
            st.markdown(f"""
            <div style='padding: 0.5rem; margin: 0.3rem 0;'>
                <p style='color: {color}; margin: 0; font-size: 0.95rem;'>
                    {icon} {text}
                </p>
            </div>
            """, unsafe_allow_html=True)
    
    # Route to correct page
    if st.session_state.page == 1:
        page_upload()
    elif st.session_state.page == 2:
        page_chatbot()
    elif st.session_state.page == 3:
        page_proposal()


# ============================================
# Run App
# ============================================
if __name__ == "__main__":
    main()